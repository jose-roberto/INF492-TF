{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce36f64",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b58c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fdb16",
   "metadata": {},
   "source": [
    "# Checking device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968185e4-1d13-4c6e-a349-d6c63f7d8ffa",
   "metadata": {},
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe7d2c-4b3e-4718-b4a6-b03817c3710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {\n",
    "    \"experiment\": \"resnet50-700-SGD-CELoss\",\n",
    "    \"num_classes\": 700,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_workers\": 1,\n",
    "    \"criterion\": nn.CrossEntropyLoss(),\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"momentum\": 0.9,\n",
    "    \"max_epochs\": 10\n",
    "}\n",
    "\n",
    "folder = f\"./experiments/{setup['experiment']}\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "file_path = os.path.join(folder, 'setup.txt')\n",
    "\n",
    "with open(file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(setup, f, indent=4, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"Saved in: {file_path}\")\n",
    "\n",
    "tensorboard_path = f'./experiments/{setup[\"experiment\"]}/tensorboard/'\n",
    "models_path = f\"./experiments/{setup['experiment']}/models/\"\n",
    "\n",
    "os.makedirs(os.path.join(tensorboard_path), exist_ok=True)\n",
    "os.makedirs(os.path.join(models_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852cfbd7",
   "metadata": {},
   "source": [
    "# Tensorboard functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_net_attributes(epoch, net, writer):\n",
    "    layers = list(net.modules())\n",
    "\n",
    "    layer_id = 1\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, nn.Linear) :\n",
    "            writer.add_histogram(f'Bias/linear-{layer_id}', layer.bias, epoch )\n",
    "            writer.add_histogram(f'Weight/linear-{layer_id}', layer.weight, epoch )\n",
    "            writer.add_histogram(f'Grad/linear-{layer_id}', layer.weight.grad, epoch )\n",
    "            layer_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72badf21-94d1-466c-a124-626c1bee6e1e",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e228d-7efe-4639-bff7-09957f8ce618",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96663ee7-6438-45b4-b3ce-4bdb09efd02d",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164f261-6dc8-46d1-9a26-424a76555530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform_view = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "img_dir  = \"../dataset/nabirds/versions/1/images/0295\"\n",
    "\n",
    "img_files = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "N = 4\n",
    "img_files = img_files[:N]\n",
    "\n",
    "cols = 2\n",
    "rows = N // cols + int(N % cols != 0)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 4*rows))\n",
    "\n",
    "for idx, img_fname in enumerate(img_files):\n",
    "    pil = Image.open(os.path.join(img_dir, img_fname)).convert(\"RGB\")\n",
    "\n",
    "    out = train_transform_view(pil)\n",
    "    out = out.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    r, c = divmod(idx, cols)\n",
    "    ax = axes[r, c]\n",
    "    ax.imshow(out)\n",
    "    ax.set_title(f\"Image {idx+1}\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af0aaf-8f86-4bda-b98d-e71fbdba6cf7",
   "metadata": {},
   "source": [
    "# NaBird"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75724155-504d-4c96-a919-9c6c2294afc5",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e0d89-f59e-40ce-8b1c-8d4dc5dbfee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NABirdsDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None, remap_labels=True):\n",
    "        \"\"\"\n",
    "        Dataset para as N categorias que realmente aparecem.\n",
    "        Se remap_labels=True, vai comprimir os labels para 0..(N-1).\n",
    "        \"\"\"\n",
    "        self.root      = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 1) carrega image_id → caminho\n",
    "        self.id2path = {}\n",
    "        with open(os.path.join(root_dir, \"images.txt\"), \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts)!=2: continue\n",
    "                img_id, rel = parts\n",
    "                self.id2path[img_id] = rel\n",
    "\n",
    "        # 2) carrega image_id → rótulo original (0-based)\n",
    "        raw_id2label = {}\n",
    "        with open(os.path.join(root_dir, \"image_class_labels.txt\"), \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts)!=2: continue\n",
    "                img_id, cls = parts\n",
    "                raw_id2label[img_id] = int(cls) - 1\n",
    "\n",
    "        # 3) monta lista crua de samples (antes de remapear)\n",
    "        flag_target = '1' if split=='train' else '0'\n",
    "        raw_samples = []\n",
    "        with open(os.path.join(root_dir, \"train_test_split.txt\"), \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts)!=2: continue\n",
    "                img_id, flag = parts\n",
    "                if flag==flag_target and img_id in self.id2path:\n",
    "                    raw_samples.append((img_id, raw_id2label[img_id]))\n",
    "\n",
    "        # 4) se for remapear, constrói o mapeamento e aplica\n",
    "        if remap_labels:\n",
    "            # pega labels únicos e ordena\n",
    "            unique_labels = sorted({lbl for _,lbl in raw_samples})\n",
    "            # cria old->new\n",
    "            self.label_map = {old: new for new, old in enumerate(unique_labels)}\n",
    "            # nova lista de samples com labels remapeados\n",
    "            self.samples = [(img_id, self.label_map[lbl]) for img_id, lbl in raw_samples]\n",
    "            self.num_classes = len(unique_labels)\n",
    "        else:\n",
    "            self.samples = raw_samples\n",
    "            self.num_classes = max(lbl for _,lbl in raw_samples) + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, label = self.samples[idx]\n",
    "        img = Image.open(os.path.join(self.root, \"images\", self.id2path[img_id])).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "data_root = \"../dataset/nabirds/versions/1\"\n",
    "\n",
    "train_dataset = NABirdsDataset(\n",
    "    data_root,\n",
    "    split='train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = NABirdsDataset(\n",
    "    data_root,\n",
    "    split='val',\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "print(f\"Classes efetivas: {train_dataset.num_classes}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee574220-8907-4044-a02b-fef12edc9a00",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c8084-68a6-462d-a2f3-60047698dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=setup[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=setup[\"num_workers\"],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=setup[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=setup[\"num_workers\"],\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb467f9e",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5265ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.ResNet50_Weights.IMAGENET1K_V1\n",
    "\n",
    "net = models.resnet50(weights=weights)\n",
    "\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in net.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "net.fc = nn.Linear(net.fc.in_features, setup[\"num_classes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0885a20-61f3-4505-8343-859717f795eb",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d7585-3bb0-432f-ad2c-7cac55042742",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cfd562-69d0-45fb-9d29-491bf29ea001",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a34d10-8c7d-4178-bace-169bff0d803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(net, input_size=(setup['batch_size'], 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ddf664",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d954e53-49fa-49ca-86b8-88fd394cb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_dataloader, val_dataloader, device):\n",
    "  \n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "        filter(lambda p: p.requires_grad, net.parameters()),\n",
    "        lr=setup['lr'],\n",
    "        weight_decay=setup['weight_decay'],\n",
    "        momentum=setup['momentum'])\n",
    "\n",
    "    criterion = setup['criterion']\n",
    "    criterion.to(device)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=tensorboard_path)\n",
    "    writer.add_graph(net, next(iter(train_dataloader))[0].to(device))\n",
    "\n",
    "    max_accuracy = -1.0\n",
    "\n",
    "    for epoch in tqdm(range(setup['max_epochs'])):\n",
    "        \n",
    "        net.train()  \n",
    "\n",
    "        train_loss, train_accuracy = [], []\n",
    "\n",
    "        for train_batch in train_dataloader:\n",
    "            \n",
    "            train_x, train_label = train_batch\n",
    "            train_x = train_x.to(device)\n",
    "            train_label = train_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outs = net(train_x)\n",
    "    \n",
    "            loss = criterion(outs, train_label)\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predict_labels = torch.max(outs, axis=1)[1]\n",
    "            correct = torch.sum(predict_labels == train_label).item()\n",
    "            accuracy = correct/train_label.size(0)\n",
    "\n",
    "            train_accuracy.append(accuracy)\n",
    "\n",
    "            plot_net_attributes(epoch, net, writer)\n",
    "\n",
    "        train_loss = np.asarray(train_loss)\n",
    "        train_accuracy = np.asarray(train_accuracy)\n",
    "\n",
    "        val_loss, val_accuracy = validate(net, criterion, val_dataloader, device)\n",
    "\n",
    "        writer.add_scalar('Loss/train', train_loss.mean(), epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss.mean(), epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy.mean(), epoch)\n",
    "        writer.add_scalar('Accuracy/val', val_accuracy.mean(), epoch)\n",
    "            \n",
    "        if val_accuracy.mean() > max_accuracy:\n",
    "            best_model = copy.deepcopy(net)\n",
    "            max_accuracy = val_accuracy.mean()\n",
    "            print(f'Saving the model with the best accuracy: {max_accuracy:3.4f}')\n",
    "            \n",
    "        print(f'Epoch: {epoch+1:3d} | Loss/train: {train_loss.mean():3.4f}% | Accuracy/train: {train_accuracy.mean():3.4f}% |\\\n",
    "            Loss/val: {val_loss.mean():3.4f}% | Accuracy/val: {val_accuracy.mean():3.4f}% |')\n",
    "\n",
    "    path = f'{models_path}{setup[\"experiment\"]}-{max_accuracy:.2f}.pkl'\n",
    "    torch.save(best_model, path)\n",
    "    print(f'Best model saved in: {path}')\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ad08c",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b144e35-8d05-44bd-892b-b61118c4b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, criterion, val_dataloader, device):\n",
    "\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "\n",
    "    val_loss, val_accuracy = [], []\n",
    "\n",
    "    for test_batch in val_dataloader:\n",
    "\n",
    "        test_x, test_label = test_batch\n",
    "        test_x = test_x.to(device)\n",
    "        test_label = test_label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs = net(test_x).detach()\n",
    "\n",
    "            loss = criterion(outs, test_label)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "    \n",
    "            predict_labels = torch.max(outs, axis=1)[1]\n",
    "            correct = torch.sum(predict_labels == test_label).item()\n",
    "            accuracy = correct/test_label.size(0)\n",
    "    \n",
    "            val_accuracy.append(accuracy)\n",
    "        \n",
    "    val_loss = np.asarray(val_loss)\n",
    "    val_accuracy = np.asarray(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b212b97",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = train(net, train_dataloader, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6a9d6-7916-42a1-8389-bb3ac426be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prithvi_finetuning)",
   "language": "python",
   "name": "prithvi_finetuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
