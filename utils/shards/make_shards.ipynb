{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a0e02c-81cf-44a9-8061-fc28c4386eca",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5a232-c354-4af7-b3c4-07a820c9ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import INaturalist\n",
    "\n",
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f970fd6-1f8b-4de6-b0fe-54a11338ecb9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ea609-d79c-4ef3-95a5-b120e46bdc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../dataset/species/'\n",
    "\n",
    "train_dataset = INaturalist(\n",
    "    root=dataset_path,\n",
    "    version='2021_train_mini',\n",
    "    download=False\n",
    ")\n",
    "\n",
    "test_dataset = INaturalist(\n",
    "    root=dataset_path,\n",
    "    version='2021_valid',\n",
    "    download=False\n",
    ")\n",
    "\n",
    "print(train_dataset)\n",
    "print(\"\\nTrain sample:\")\n",
    "train_sample = train_dataset[0]\n",
    "print(train_sample[0].shape)\n",
    "print()\n",
    "\n",
    "print(test_dataset)\n",
    "print(\"\\nTest sample:\")\n",
    "test_sample = test_dataset[0]\n",
    "print(test_sample[0].shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c1ab9-29e0-44c7-a218-dc54d226b14b",
   "metadata": {},
   "source": [
    "# Shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1bd769-7dd2-4f66-acf2-c88c85715da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_dir = os.path.join(dataset_path, \"shards\")\n",
    "\n",
    "samples_per_shard = 10000  \n",
    "\n",
    "def create_shards(dataset, train, out_dir, samples_per_shard: int):\n",
    "    split = \"train\" if train else \"test\"\n",
    "    \n",
    "    split_dir = os.path.join(out_dir, split)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    \n",
    "    writer = wds.ShardWriter(\n",
    "        os.path.join(split_dir, \"data-%06d.tar\"),\n",
    "        maxcount=samples_per_shard\n",
    "    )\n",
    "    \n",
    "    to_pil = T.ToPILImage()\n",
    "    for idx, (img, label) in enumerate(dataset):\n",
    "        if not hasattr(img, \"save\"):\n",
    "            img = to_pil(img)\n",
    "            \n",
    "        key = f\"{idx:08d}\"\n",
    "        buffer_io = io.BytesIO()\n",
    "        img.save(buffer_io, format=\"JPEG\")\n",
    "        buffer = buffer_io.getvalue()\n",
    "        \n",
    "        sample = {\n",
    "            \"__key__\": key,\n",
    "            \"jpg\": buffer,\n",
    "            \"cls\": str(label).encode(\"utf-8\"),\n",
    "        }\n",
    "        \n",
    "        writer.write(sample)\n",
    "        \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "if not os.path.isdir(shard_dir) or len(os.listdir(shard_dir)) == 0:\n",
    "    print(\"Criando shards...\")\n",
    "    \n",
    "    create_shards(train_dataset, True, shard_dir, samples_per_shard)\n",
    "    \n",
    "    create_shards(test_dataset, False, shard_dir, samples_per_shard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (inf492)",
   "language": "python",
   "name": "inf492"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
