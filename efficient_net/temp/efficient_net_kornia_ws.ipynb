{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce36f64",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16b58c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import kornia.augmentation as K\n",
    "import kornia.color as C\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from torchvision.datasets import INaturalist\n",
    "from torchvision import models\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fdb16",
   "metadata": {},
   "source": [
    "# Checking device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a03701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available? True\n",
      "Device name: NVIDIA GeForce RTX 4090\n",
      "Current device: 0\n",
      "Using: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968185e4-1d13-4c6e-a349-d6c63f7d8ffa",
   "metadata": {},
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fe7d2c-4b3e-4718-b4a6-b03817c3710f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in: ./experiments/efficientnet_b4-10000-SGD-CELoss/setup.txt\n"
     ]
    }
   ],
   "source": [
    "setup = {\n",
    "    \"experiment\": \"efficientnet_b4-10000-SGD-CELoss\",\n",
    "    \"num_classes\": 10000,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_workers\": 8,\n",
    "    \"prefetch_factor\": 2,\n",
    "    \"criterion\": nn.CrossEntropyLoss(),\n",
    "    \"lr\": 1e-3,\n",
    "    \"lambda_reg\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"max_epochs\": 5\n",
    "}\n",
    "\n",
    "folder = f\"./experiments/{setup['experiment']}\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "file_path = os.path.join(folder, \"setup.txt\")\n",
    "\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(setup, f, indent=4, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"Saved in: {file_path}\")\n",
    "\n",
    "os.makedirs(os.path.join(f\"./experiments/{setup['experiment']}/tensorboard\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(f\"./experiments/{setup['experiment']}/models\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852cfbd7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58fe4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layers(efficientnet_b4, writer, epoch):\n",
    "    layers = list(efficientnet_b4.modules())\n",
    "\n",
    "    layer_id = 1\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            writer.add_histogram(f'Bias/linear-{layer_id}', layer.bias, epoch)\n",
    "            writer.add_histogram(f'Weight/linear-{layer_id}', layer.weight, epoch)\n",
    "            writer.add_histogram(f'Grad/linear-{layer_id}', layer.weight.grad, epoch)\n",
    "            layer_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72badf21-94d1-466c-a124-626c1bee6e1e",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8e228d-7efe-4639-bff7-09957f8ce618",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.4650194027653909, 0.48128506681789435, 0.37711871442015105]\n",
    "std = [0.24237112423460933, 0.23366727265227194, 0.25144634756835477]\n",
    "\n",
    "class Div255(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x / 255.0\n",
    "\n",
    "class ToTensorModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.to_tensor = ToTensor()\n",
    "    def forward(self, x):\n",
    "        return self.to_tensor(x)\n",
    "\n",
    "train_transform = torch.nn.Sequential(\n",
    "    ToTensorModule(),\n",
    "    \n",
    "    K.RandomCrop((224,224)),\n",
    "    \n",
    "    K.RandomHorizontalFlip(p=0.5),\n",
    "    K.RandomVerticalFlip(p=0.5),\n",
    "    K.RandomPerspective(p=0.2),\n",
    "    \n",
    "    K.RandomGaussianBlur((3,3), sigma=(0.3, 1.0)),\n",
    "    K.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    K.RandomBrightness(brightness=(0.8,1.2), p=0.3),\n",
    " \n",
    "    K.Normalize(mean=mean, std=std, p=1.0)\n",
    ")\n",
    "\n",
    "test_transform = torch.nn.Sequential(\n",
    "    ToTensorModule(),\n",
    "    \n",
    "    K.CenterCrop((224,224)),\n",
    "    \n",
    "    K.Normalize(mean=mean, std=std, p=1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96663ee7-6438-45b4-b3ce-4bdb09efd02d",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0164f261-6dc8-46d1-9a26-424a76555530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transform_view = torch.nn.Sequential(\n",
    "#     ToTensorModule(),\n",
    "    \n",
    "#     K.Resize((224,224)),\n",
    "\n",
    "#     K.RandomHorizontalFlip(p=1.0),\n",
    "#     K.RandomVerticalFlip(p=1.0),\n",
    "#     K.RandomPerspective(p=1.0),\n",
    "    \n",
    "#     K.RandomGaussianBlur((3,3), sigma=(0.3, 1.0)),\n",
    "#     K.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "#     K.RandomBrightness(brightness=(0.8,1.2), p=1.0),\n",
    "# )\n",
    "\n",
    "# img_dir  = \"../dataset/2021_train_mini/00000_Animalia_Annelida_Clitellata_Haplotaxida_Lumbricidae_Lumbricus_terrestris\"\n",
    "\n",
    "# img_files = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "# N = 4\n",
    "# img_files = img_files[:N]\n",
    "\n",
    "# cols = 2\n",
    "# rows = N // cols + int(N % cols != 0)\n",
    "\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 4*rows))\n",
    "\n",
    "# for idx, img_fname in enumerate(img_files):\n",
    "#     pil = Image.open(os.path.join(img_dir, img_fname)).convert(\"RGB\")\n",
    "#     t = pil_to_tensor(pil).float().to(device).unsqueeze(0)\n",
    "\n",
    "#     out = train_transform_view(t)\n",
    "#     out = out.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "#     r, c = divmod(idx, cols)\n",
    "#     ax = axes[r, c]\n",
    "#     ax.imshow(out)\n",
    "#     ax.set_title(f\"Image {idx+1}\")\n",
    "#     ax.axis(\"off\")\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc90025",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa8968-99dd-4070-8f77-2637d4a4131d",
   "metadata": {},
   "source": [
    "## Make dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dbd9125-ca7c-402d-bb5c-1d5e77c293dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_dir = os.path.join(\"../dataset\", \"shards\")\n",
    "\n",
    "def decode_label(b):\n",
    "    if isinstance(b, (bytes, bytearray)):\n",
    "        return torch.tensor(int(b.decode('utf-8')), dtype=torch.long)\n",
    "    elif isinstance(b, int):\n",
    "        return torch.tensor(b, dtype=torch.long)\n",
    "    else:\n",
    "        raise TypeError(f\"Tipo inesperado: {type(b)}\")\n",
    "\n",
    "def make_dataloader(train, filenames):\n",
    "    if train:\n",
    "        split = \"train\"\n",
    "        transforms = train_transform\n",
    "        num_workers = setup['num_workers']\n",
    "    else:\n",
    "        split = \"test\"\n",
    "        transforms = test_transform\n",
    "        num_workers = int(setup['num_workers'] / 2)\n",
    "        \n",
    "    pattern = os.path.join(shard_dir, split, filenames)\n",
    "    \n",
    "    dataset = (\n",
    "        wds.WebDataset(pattern, shardshuffle=False)\n",
    "        .shuffle(2000)\n",
    "        .decode(\"pil\")\n",
    "        .to_tuple(\"jpg\", \"cls\")\n",
    "        .map_tuple(transforms, decode_label)\n",
    "        .batched(setup['batch_size'], partial=torch.stack)\n",
    "    )\n",
    "    \n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=None,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=setup['prefetch_factor'],\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "train_dataloader = make_dataloader(train=True, filenames=\"data-{000000..000049}.tar\")\n",
    "\n",
    "test_dataloader = make_dataloader(train=False, filenames=\"data-{000000..000009}.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab97cf1-b807-4e71-a79f-f4df66aad225",
   "metadata": {},
   "source": [
    "## Get class names and size of data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c50f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = INaturalist(\n",
    "    root='../dataset/',\n",
    "    version='2021_train_mini',\n",
    "    transform=train_transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "test_dataset = INaturalist(\n",
    "    root='../dataset/',\n",
    "    version='2021_valid',\n",
    "    transform=test_transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "class_names = train_dataset.all_categories\n",
    "\n",
    "short_class_names = [c.split(\"_\")[-2] + \" \" + c.split(\"_\")[-1] \n",
    "               for c in train_dataset.all_categories]\n",
    "\n",
    "train_dataset_size = len(train_dataset)\n",
    "train_dataloader_size = math.ceil(train_dataset_size / setup['batch_size'])\n",
    "\n",
    "test_dataset_size = len(test_dataset)\n",
    "test_dataloader_size = math.ceil(test_dataset_size / setup['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb467f9e",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db5265ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.EfficientNet_B4_Weights.IMAGENET1K_V1\n",
    "\n",
    "efficientnet_b4 = models.efficientnet_b4(weights=weights)\n",
    "\n",
    "for param in efficientnet_b4.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = efficientnet_b4.classifier[1].in_features\n",
    "efficientnet_b4.classifier[1] = nn.Linear(num_features, setup['num_classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0885a20-61f3-4505-8343-859717f795eb",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984d7585-3bb0-432f-ad2c-7cac55042742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=True)\n",
      "  (1): Linear(in_features=1792, out_features=10000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(efficientnet_b4.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36cfd562-69d0-45fb-9d29-491bf29ea001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.1.weight True\n",
      "classifier.1.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in efficientnet_b4.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a34d10-8c7d-4178-bace-169bff0d803b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "EfficientNet                                            [64, 10000]               --\n",
       "├─Sequential: 1-1                                       [64, 1792, 7, 7]          --\n",
       "│    └─Conv2dNormActivation: 2-1                        [64, 48, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-1                                 [64, 48, 112, 112]        (1,296)\n",
       "│    │    └─BatchNorm2d: 3-2                            [64, 48, 112, 112]        (96)\n",
       "│    │    └─SiLU: 3-3                                   [64, 48, 112, 112]        --\n",
       "│    └─Sequential: 2-2                                  [64, 24, 112, 112]        --\n",
       "│    │    └─MBConv: 3-4                                 [64, 24, 112, 112]        (2,940)\n",
       "│    │    └─MBConv: 3-5                                 [64, 24, 112, 112]        (1,206)\n",
       "│    └─Sequential: 2-3                                  [64, 32, 56, 56]          --\n",
       "│    │    └─MBConv: 3-6                                 [64, 32, 56, 56]          (11,878)\n",
       "│    │    └─MBConv: 3-7                                 [64, 32, 56, 56]          (18,120)\n",
       "│    │    └─MBConv: 3-8                                 [64, 32, 56, 56]          (18,120)\n",
       "│    │    └─MBConv: 3-9                                 [64, 32, 56, 56]          (18,120)\n",
       "│    └─Sequential: 2-4                                  [64, 56, 28, 28]          --\n",
       "│    │    └─MBConv: 3-10                                [64, 56, 28, 28]          (25,848)\n",
       "│    │    └─MBConv: 3-11                                [64, 56, 28, 28]          (57,246)\n",
       "│    │    └─MBConv: 3-12                                [64, 56, 28, 28]          (57,246)\n",
       "│    │    └─MBConv: 3-13                                [64, 56, 28, 28]          (57,246)\n",
       "│    └─Sequential: 2-5                                  [64, 112, 14, 14]         --\n",
       "│    │    └─MBConv: 3-14                                [64, 112, 14, 14]         (70,798)\n",
       "│    │    └─MBConv: 3-15                                [64, 112, 14, 14]         (197,820)\n",
       "│    │    └─MBConv: 3-16                                [64, 112, 14, 14]         (197,820)\n",
       "│    │    └─MBConv: 3-17                                [64, 112, 14, 14]         (197,820)\n",
       "│    │    └─MBConv: 3-18                                [64, 112, 14, 14]         (197,820)\n",
       "│    │    └─MBConv: 3-19                                [64, 112, 14, 14]         (197,820)\n",
       "│    └─Sequential: 2-6                                  [64, 160, 14, 14]         --\n",
       "│    │    └─MBConv: 3-20                                [64, 160, 14, 14]         (240,924)\n",
       "│    │    └─MBConv: 3-21                                [64, 160, 14, 14]         (413,160)\n",
       "│    │    └─MBConv: 3-22                                [64, 160, 14, 14]         (413,160)\n",
       "│    │    └─MBConv: 3-23                                [64, 160, 14, 14]         (413,160)\n",
       "│    │    └─MBConv: 3-24                                [64, 160, 14, 14]         (413,160)\n",
       "│    │    └─MBConv: 3-25                                [64, 160, 14, 14]         (413,160)\n",
       "│    └─Sequential: 2-7                                  [64, 272, 7, 7]           --\n",
       "│    │    └─MBConv: 3-26                                [64, 272, 7, 7]           (520,904)\n",
       "│    │    └─MBConv: 3-27                                [64, 272, 7, 7]           (1,159,332)\n",
       "│    │    └─MBConv: 3-28                                [64, 272, 7, 7]           (1,159,332)\n",
       "│    │    └─MBConv: 3-29                                [64, 272, 7, 7]           (1,159,332)\n",
       "│    │    └─MBConv: 3-30                                [64, 272, 7, 7]           (1,159,332)\n",
       "│    │    └─MBConv: 3-31                                [64, 272, 7, 7]           (1,159,332)\n",
       "│    │    └─MBConv: 3-32                                [64, 272, 7, 7]           (1,159,332)\n",
       "│    │    └─MBConv: 3-33                                [64, 272, 7, 7]           (1,159,332)\n",
       "│    └─Sequential: 2-8                                  [64, 448, 7, 7]           --\n",
       "│    │    └─MBConv: 3-34                                [64, 448, 7, 7]           (1,420,804)\n",
       "│    │    └─MBConv: 3-35                                [64, 448, 7, 7]           (3,049,200)\n",
       "│    └─Conv2dNormActivation: 2-9                        [64, 1792, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-36                                [64, 1792, 7, 7]          (802,816)\n",
       "│    │    └─BatchNorm2d: 3-37                           [64, 1792, 7, 7]          (3,584)\n",
       "│    │    └─SiLU: 3-38                                  [64, 1792, 7, 7]          --\n",
       "├─AdaptiveAvgPool2d: 1-2                                [64, 1792, 1, 1]          --\n",
       "├─Sequential: 1-3                                       [64, 10000]               --\n",
       "│    └─Dropout: 2-10                                    [64, 1792]                --\n",
       "│    └─Linear: 2-11                                     [64, 10000]               17,930,000\n",
       "=========================================================================================================\n",
       "Total params: 35,478,616\n",
       "Trainable params: 17,930,000\n",
       "Non-trainable params: 17,548,616\n",
       "Total mult-adds (Units.GIGABYTES): 97.28\n",
       "=========================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 17444.31\n",
       "Params size (MB): 141.91\n",
       "Estimated Total Size (MB): 17624.76\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(efficientnet_b4, input_size=(setup['batch_size'], 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ddf664",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3c0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    tensorboard_path = f'experiments/{setup[\"experiment\"]}/tensorboard/'\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=tensorboard_path)\n",
    "    \n",
    "    efficientnet_b4.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "        filter(lambda p: p.requires_grad, efficientnet_b4.parameters()),\n",
    "        lr=setup['lr'],\n",
    "        weight_decay=setup['lambda_reg'],\n",
    "        momentum=setup['momentum'])\n",
    "    \n",
    "    criterion = setup['criterion']\n",
    "    \n",
    "    accuracies = []\n",
    "    max_accuracy = -1.0\n",
    "\n",
    "    writer.add_graph(efficientnet_b4, input_to_model=next(iter(train_dataloader))[0].to(device))\n",
    "    \n",
    "    for epoch in tqdm(range(setup[\"max_epochs\"])):\n",
    "\n",
    "        accumulated_loss_train = 0.0\n",
    "\n",
    "        train_accuracies = []\n",
    "\n",
    "        efficientnet_b4.train()\n",
    "        \n",
    "        for train_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_x, train_label = train_batch\n",
    "            train_x = train_x.to(device)\n",
    "            train_label = train_label.to(device)\n",
    "\n",
    "            predicts = efficientnet_b4(train_x)\n",
    "\n",
    "            loss = criterion(predicts, train_label.long())\n",
    "            accumulated_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            predict_labels = torch.max(predicts, axis=1)[1]\n",
    "            correct = torch.sum(predict_labels == train_label)\n",
    "            accuracy_train = correct/train_label.size(0)\n",
    "\n",
    "            train_accuracies.append(accuracy_train)\n",
    "\n",
    "        full_loss_train = accumulated_loss_train / train_dataloader_size\n",
    "\n",
    "        avg_train_acurracie = sum(train_accuracies) / train_dataloader_size\n",
    "\n",
    "        test_loss, accuracy_test = validate(efficientnet_b4, criterion, test_dataloader, writer, epoch)\n",
    "        accuracies.append(accuracy_test)\n",
    "\n",
    "        if accuracy_test > max_accuracy:\n",
    "            best_model = copy.deepcopy(efficientnet_b4)\n",
    "            max_accuracy = accuracy_test\n",
    "            print(f'Saving: Best model at epoch {epoch+1:3d} | Accuracy: {accuracy_test:8.4f}%')\n",
    "    \n",
    "        print(f'Epoch: {epoch + 1:3d} | Accuracy Test: {accuracy_test:3.4f}%')\n",
    "\n",
    "        writer.add_scalar('Loss/train', full_loss_train, epoch)\n",
    "        writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', avg_train_acurracie, epoch)\n",
    "        writer.add_scalar('Accuracy/test', accuracy_test, epoch)\n",
    "\n",
    "        plot_layers(efficientnet_b4, writer, epoch)\n",
    "   \n",
    "    models_path = f\"./experiments/{setup['experiment']}/models/\"\n",
    "    path = f'{models_path}{setup[\"experiment\"]}-{max_accuracy:.2f}.pkl'\n",
    "    torch.save(best_model, path)\n",
    "    print(f'Model saved in: {path}')\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ad08c",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cdf9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, criterion, test_dataloader, writer, epoch):\n",
    "\n",
    "    accumulated_loss_test = 0.0\n",
    "    test_accuracies = []\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    images_to_plot = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, test_batch in enumerate(test_dataloader):\n",
    "            \n",
    "            test_x, test_label = test_batch\n",
    "            test_x = test_x.to(device)\n",
    "            test_label = test_label.to(device)\n",
    "            \n",
    "            predicts = net(test_x).detach()\n",
    "            loss = criterion(predicts, test_label)\n",
    "            accumulated_loss_test += loss.item()\n",
    "    \n",
    "            predict_labels = torch.max(predicts, axis=1)[1]\n",
    "            correct = torch.sum(predict_labels == test_label)\n",
    "            accuracy_val = correct/test_label.size(0)\n",
    "    \n",
    "            test_accuracies.append(accuracy_val.to('cpu').numpy())\n",
    "\n",
    "    avg_loss = accumulated_loss_test / test_dataloader_size\n",
    "    accuracy = (sum(test_accuracies) * 100) / test_dataloader_size\n",
    "    \n",
    "    return avg_loss, accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b212b97",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cf7f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 1, 3, 224, 224]\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 1, 3, 224, 224]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_model = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     16\u001b[39m accuracies = []\n\u001b[32m     17\u001b[39m max_accuracy = -\u001b[32m1.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mefficientnet_b4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(setup[\u001b[33m\"\u001b[39m\u001b[33mmax_epochs\u001b[39m\u001b[33m\"\u001b[39m])):\n\u001b[32m     23\u001b[39m     accumulated_loss_train = \u001b[32m0.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/utils/tensorboard/writer.py:841\u001b[39m, in \u001b[36mSummaryWriter.add_graph\u001b[39m\u001b[34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[39m\n\u001b[32m    838\u001b[39m torch._C._log_api_usage_once(\u001b[33m\"\u001b[39m\u001b[33mtensorboard.logging.add_graph\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    839\u001b[39m \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[32m    840\u001b[39m \u001b[38;5;28mself\u001b[39m._get_file_writer().add_graph(\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/utils/tensorboard/_pytorch_graph.py:337\u001b[39m, in \u001b[36mgraph\u001b[39m\u001b[34m(model, args, verbose, use_strict_trace)\u001b[39m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[32m    336\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mError occurs, No graph saved\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28mprint\u001b[39m(graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/utils/tensorboard/_pytorch_graph.py:331\u001b[39m, in \u001b[36mgraph\u001b[39m\u001b[34m(model, args, verbose, use_strict_trace)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         trace = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m         graph = trace.graph\n\u001b[32m    333\u001b[39m         torch._C._jit_pass_inline(graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/jit/_trace.py:1002\u001b[39m, in \u001b[36mtrace\u001b[39m\u001b[34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[39m\n\u001b[32m    989\u001b[39m     warnings.warn(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`optimize` is deprecated and has no effect. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse `with torch.jit.optimized_execution()` instead\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    992\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    993\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    994\u001b[39m     )\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    997\u001b[39m     check_if_torch_exportable,\n\u001b[32m    998\u001b[39m     log_torch_jit_trace_exportability,\n\u001b[32m    999\u001b[39m     log_torchscript_usage,\n\u001b[32m   1000\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m traced_func = \u001b[43m_trace_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m log_torchscript_usage(\u001b[33m\"\u001b[39m\u001b[33mtrace\u001b[39m\u001b[33m\"\u001b[39m, model_id=_get_model_id(traced_func))\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_if_torch_exportable():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/jit/_trace.py:698\u001b[39m, in \u001b[36m_trace_impl\u001b[39m\u001b[34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[39m\n\u001b[32m    696\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    697\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mexample_kwarg_inputs should be a dict\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    712\u001b[39m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[33m\"\u001b[39m\u001b[33m__self__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func.\u001b[34m__self__\u001b[39m, torch.nn.Module)\n\u001b[32m    714\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    715\u001b[39m ):\n\u001b[32m    716\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/jit/_trace.py:1278\u001b[39m, in \u001b[36mtrace_module\u001b[39m\u001b[34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[39m\n\u001b[32m   1276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1277\u001b[39m     example_inputs = make_tuple(example_inputs)\n\u001b[32m-> \u001b[39m\u001b[32m1278\u001b[39m     \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_c\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1289\u001b[39m check_trace_method = module._c._get_method(method_name)\n\u001b[32m   1291\u001b[39m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1726\u001b[39m, in \u001b[36mModule._slow_forward\u001b[39m\u001b[34m(self, *input, **kwargs)\u001b[39m\n\u001b[32m   1724\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1725\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1726\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1728\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torchvision/models/efficientnet.py:343\u001b[39m, in \u001b[36mEfficientNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torchvision/models/efficientnet.py:333\u001b[39m, in \u001b[36mEfficientNet._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.avgpool(x)\n\u001b[32m    336\u001b[39m     x = torch.flatten(x, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1726\u001b[39m, in \u001b[36mModule._slow_forward\u001b[39m\u001b[34m(self, *input, **kwargs)\u001b[39m\n\u001b[32m   1724\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1725\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1726\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1728\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1726\u001b[39m, in \u001b[36mModule._slow_forward\u001b[39m\u001b[34m(self, *input, **kwargs)\u001b[39m\n\u001b[32m   1724\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1725\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1726\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1728\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/module.py:1726\u001b[39m, in \u001b[36mModule._slow_forward\u001b[39m\u001b[34m(self, *input, **kwargs)\u001b[39m\n\u001b[32m   1724\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1725\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1726\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1728\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/homeLocal/jroberto/anaconda3/envs/inf492/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 1, 3, 224, 224]"
     ]
    }
   ],
   "source": [
    "best_model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6a9d6-7916-42a1-8389-bb3ac426be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (inf492)",
   "language": "python",
   "name": "inf492"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
